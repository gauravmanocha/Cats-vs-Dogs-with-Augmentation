{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats-vs-Dogs-with-Augmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LRjER02nY2f",
        "colab_type": "text"
      },
      "source": [
        "Let's begin with the code...\n",
        "\n",
        "Downloading the Cats VS Dogs Dataset in a temperory zip folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lehcbkSVnWY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTSuCtk0nnGy",
        "colab_type": "text"
      },
      "source": [
        "Importing all the libraries required for the model to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd7vVWebnXDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIE6PNHYnwQL",
        "colab_type": "text"
      },
      "source": [
        "Unzipping the Zipped Dataset. The Dataset contains two sub-folders namely:\n",
        "\n",
        "train\n",
        "validation\n",
        "Inside these both sub-folders, there are two another sub-folders named cats and dogs.\n",
        "\n",
        "The train folder contains images of cats and dogs for training of the model.\n",
        "\n",
        "The validation folder contains images of cats and dogs for validating the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0WhxJyRnXF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE2HbRoNn5_d",
        "colab_type": "text"
      },
      "source": [
        "Including 4 Convulotion layers with 32, 64, 128, 128 Convulotions respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNGqDH0RnXIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([ keras.layers.Conv2D(32,(3,3), input_shape=(150,150,3), activation='relu'),\n",
        "                                  keras.layers.MaxPool2D(2,2),\n",
        "                                  keras.layers.Conv2D(64,(3,3), activation='relu'),\n",
        "                                  keras.layers.MaxPool2D(2,2),\n",
        "                                  keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "                                  keras.layers.MaxPool2D(2,2),\n",
        "                                  keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
        "                                  keras.layers.MaxPool2D(2,2),\n",
        "                                  keras.layers.Flatten(),\n",
        "                                  keras.layers.Dense(128 , activation='relu'),\n",
        "                                  keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEU5DxLbnXK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = RMSprop(lr=1e-4) , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly25H_6uoKPS",
        "colab_type": "text"
      },
      "source": [
        "Keras's ImageDataGenerator helps in augmentation of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJkS0xBrnXNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1/255 , rotation_range=0.2 , horizontal_flip=True, shear_range=0.2,\n",
        "                                   width_shift_range= 0.2, height_shift_range= 0.2, zoom_range=0.2, fill_mode = 'nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode='binary',\n",
        "    target_size = (150,150)\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    batch_size = 20,\n",
        "    class_mode='binary',\n",
        "    target_size = (150,150)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLnMo8jVnXQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_gen, steps_per_epoch=100, epochs=100, validation_data=test_gen, validation_steps=50 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQVAVnHoZHo",
        "colab_type": "text"
      },
      "source": [
        "Plotting both Accuracy and Validation Accuracy and Loss and Validation Loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVx1EYkhnXT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAgUe7jfnXBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)\n",
        "  if classes>[0.5]:\n",
        "    print(fn , \"is a dog\")\n",
        "  else:\n",
        "    print(fn , \"is a cat\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}